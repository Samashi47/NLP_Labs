{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2\n",
    "**Author :** ***Ahmed Samady***\\\n",
    "**Supervised by :** ***Pr. Lotfi El Aachak***\\\n",
    "**Course :** ***NLP***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Language Modeling - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading file into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>High risk problems are address in the prototyp...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>To simulate portions of the desired final prod...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>A prototype program simulates the behaviors of...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>Defined in the Specification phase a prototype...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>It is used to let the users have a first idea ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>12.1</td>\n",
       "      <td>log n</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>12.1</td>\n",
       "      <td>minus 1 divided by 2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>12.1</td>\n",
       "      <td>2n-1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440</th>\n",
       "      <td>12.1</td>\n",
       "      <td>it takes at most h steps, where h is the heigh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>12.1</td>\n",
       "      <td>it depends on the install search tree then fro...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2442 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             answer  score  correct\n",
       "0      1.1  High risk problems are address in the prototyp...    3.5      0.0\n",
       "1      1.1  To simulate portions of the desired final prod...    5.0      1.0\n",
       "2      1.1  A prototype program simulates the behaviors of...    4.0      1.0\n",
       "3      1.1  Defined in the Specification phase a prototype...    5.0      1.0\n",
       "4      1.1  It is used to let the users have a first idea ...    3.0      0.0\n",
       "...    ...                                                ...    ...      ...\n",
       "2437  12.1                                              log n    5.0      1.0\n",
       "2438  12.1                               minus 1 divided by 2    1.5      0.0\n",
       "2439  12.1                                               2n-1    2.5      0.0\n",
       "2440  12.1  it takes at most h steps, where h is the heigh...    5.0      1.0\n",
       "2441  12.1  it depends on the install search tree then fro...    1.5      0.0\n",
       "\n",
       "[2442 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/answers.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "11.1    60\n",
       "12.1    56\n",
       "3.7     31\n",
       "3.6     31\n",
       "3.5     31\n",
       "        ..\n",
       "10.4    24\n",
       "10.3    24\n",
       "10.2    24\n",
       "10.1    24\n",
       "10.6    24\n",
       "Name: count, Length: 85, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing only the answers for a specific question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['id'] == 11.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    60.000000\n",
       "mean      4.408333\n",
       "std       0.865985\n",
       "min       1.500000\n",
       "25%       4.000000\n",
       "50%       5.000000\n",
       "75%       5.000000\n",
       "max       5.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing punctuations and lowercasing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ah-ma\\AppData\\Local\\Temp\\ipykernel_22008\\1218890646.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['answer'] = data['answer'].apply(lambda x: \\\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>11.1</td>\n",
       "      <td>the name of the class file the parameters it m...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>11.1</td>\n",
       "      <td>access specifiers and functions oftentimes a c...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>11.1</td>\n",
       "      <td>the elements typically included in a class def...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>11.1</td>\n",
       "      <td>class is user defined it contains members data...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>11.1</td>\n",
       "      <td>member functions and data members</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             answer  score  correct\n",
       "1862  11.1  the name of the class file the parameters it m...    3.0      0.0\n",
       "1863  11.1  access specifiers and functions oftentimes a c...    3.0      0.0\n",
       "1864  11.1  the elements typically included in a class def...    5.0      1.0\n",
       "1865  11.1  class is user defined it contains members data...    4.0      1.0\n",
       "1866  11.1                  member functions and data members    5.0      1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['answer'] = data['answer'].apply(lambda x: \\\n",
    "    x.translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ah-ma\\AppData\\Local\\Temp\\ipykernel_22008\\993163120.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['tokenized'] = data['answer'].apply(lambda x: word_tokenize(x))\n",
      "C:\\Users\\ah-ma\\AppData\\Local\\Temp\\ipykernel_22008\\993163120.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['tokenized'] = data['tokenized'].apply(lambda x: \\\n",
      "C:\\Users\\ah-ma\\AppData\\Local\\Temp\\ipykernel_22008\\993163120.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['tokenized'] = data['tokenized'].apply(lambda x: [word for word in x if len(word) >= 3])\n",
      "C:\\Users\\ah-ma\\AppData\\Local\\Temp\\ipykernel_22008\\993163120.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop_duplicates(subset=['tokenized'],inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "      <th>score</th>\n",
       "      <th>correct</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>11.1</td>\n",
       "      <td>the name of the class file the parameters it m...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[name, class, file, parameters, must, take, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>11.1</td>\n",
       "      <td>access specifiers and functions oftentimes a c...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[access, specifiers, functions, oftentimes, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>11.1</td>\n",
       "      <td>the elements typically included in a class def...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[elements, typically, included, class, definit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>11.1</td>\n",
       "      <td>class is user defined it contains members data...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[class, user, defined, contains, members, data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>11.1</td>\n",
       "      <td>member functions and data members</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[member, functions, data, members]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             answer  score  correct  \\\n",
       "1862  11.1  the name of the class file the parameters it m...    3.0      0.0   \n",
       "1863  11.1  access specifiers and functions oftentimes a c...    3.0      0.0   \n",
       "1864  11.1  the elements typically included in a class def...    5.0      1.0   \n",
       "1865  11.1  class is user defined it contains members data...    4.0      1.0   \n",
       "1866  11.1                  member functions and data members    5.0      1.0   \n",
       "\n",
       "                                              tokenized  \n",
       "1862  [name, class, file, parameters, must, take, pe...  \n",
       "1863  [access, specifiers, functions, oftentimes, co...  \n",
       "1864  [elements, typically, included, class, definit...  \n",
       "1865  [class, user, defined, contains, members, data...  \n",
       "1866                 [member, functions, data, members]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokenized'] = data['answer'].apply(lambda x: word_tokenize(x))\n",
    "data['tokenized'] = data['tokenized'].apply(lambda x: \\\n",
    "    [word for word in x if word not in stopwords.words('english')])\n",
    "pattern = re.compile(r'\\w{1,2}')\n",
    "data['tokenized'] = data['tokenized'].apply(lambda x: [word for word in x if len(word) >= 3])\n",
    "data.drop_duplicates(subset=['tokenized'],inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862    [name, class, file, parameters, must, take, pe...\n",
       "1863    [access, specifiers, functions, oftentimes, co...\n",
       "1864    [elements, typically, included, class, definit...\n",
       "1865    [class, user, defined, contains, members, data...\n",
       "1866                   [member, functions, data, members]\n",
       "1867    [functions, variables, used, object, defined, ...\n",
       "1868    [data, members, functions, function, definitio...\n",
       "1869                    [return, type, input, parameters]\n",
       "1870                [constructor, data, members, methods]\n",
       "1871    [function, members, member, attributes, words,...\n",
       "1872    [elements, included, class, definition, access...\n",
       "1873                    [variables, function, prototypes]\n",
       "1874    [public, private, variables, initiations, func...\n",
       "1875                     [return, value, accepted, value]\n",
       "1876    [class, definition, typically, includes, class...\n",
       "1877    [parameters, type, class, name, return, type, ...\n",
       "1878         [data, members, class, variables, functions]\n",
       "1879    [constructor, functions, variables, native, cl...\n",
       "1880                           [functions, data, members]\n",
       "1881               [data, members, function, definitions]\n",
       "1883                 [constructor, function, definitions]\n",
       "1884    [class, name, data, class, definition, functio...\n",
       "1885    [class, definition, includes, definitions, cla...\n",
       "1886    [class, name, semicoln, end, defination, priva...\n",
       "1887    [constructor, private, public, variables, func...\n",
       "1888          [data, variables, functions, data, members]\n",
       "1889    [class, definitions, include, name, class, typ...\n",
       "1890      [class, variables, class, function, prototypes]\n",
       "1891             [input, address, return, type, elements]\n",
       "2132    [uses, divide, conqure, technique, recursively...\n",
       "2133    [merge, sort, works, removing, items, sepperat...\n",
       "2134    [divides, array, two, halves, sorts, half, mer...\n",
       "2135    [divide, two, sublists, sublists, break, lengt...\n",
       "2136    [merge, sort, uses, divide, conquer, idea, div...\n",
       "2137    [divides, line, half, coninuously, get, single...\n",
       "2138    [continually, split, array, half, sort, side, ...\n",
       "2139    [merge, sort, splits, array, elements, smaller...\n",
       "2140                                    [divide, conquer]\n",
       "2141    [break, single, array, many, arrays, individua...\n",
       "2142    [merge, sort, breaks, array, half, continues, ...\n",
       "2143    [merge, sort, divides, problem, half, organize...\n",
       "2144    [take, array, split, two, solve, simpler, prob...\n",
       "2145    [merge, sort, recursively, divides, array, hal...\n",
       "2146    [merge, sort, recursively, divides, array, two...\n",
       "2147    [merge, sort, continuously, breaks, array, hal...\n",
       "2148    [takes, array, splits, half, sorts, two, halve...\n",
       "2149    [splits, large, array, small, arrays, recurs, ...\n",
       "2150    [mergesort, divides, array, smaller, halves, c...\n",
       "2151    [merge, sort, breaks, array, halves, comparing...\n",
       "2152    [divides, data, twor, separate, arrays, sorts,...\n",
       "2153    [take, initial, array, split, two, temporary, ...\n",
       "2154    [merge, sort, divides, data, halves, data, one...\n",
       "2155    [merge, sort, uses, divide, conquer, strategy,...\n",
       "2156    [divide, recursuivly, big, array, two, arrays,...\n",
       "2157    [divides, array, half, sorts, half, calling, s...\n",
       "2158    [merge, sort, takes, array, splits, half, send...\n",
       "2159    [merge, sort, splits, array, two, halves, sort...\n",
       "2160    [merge, sort, continually, divides, arrayor, s...\n",
       "2161    [merge, sort, splits, array, elements, smaller...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokenized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ah-ma\\AppData\\Local\\Temp\\ipykernel_22008\\412594372.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['stemmed_tokens'] = data['tokenized'].apply(lambda x: \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1862    [name, class, file, paramet, must, take, perfo...\n",
       "1863    [access, specifi, function, oftentim, construc...\n",
       "1864    [element, typic, includ, class, definit, funct...\n",
       "1865    [class, user, defin, contain, member, data, fu...\n",
       "1866                     [member, function, data, member]\n",
       "1867       [function, variabl, use, object, defin, class]\n",
       "1868    [data, member, function, function, definit, va...\n",
       "1869                       [return, type, input, paramet]\n",
       "1870                  [constructor, data, member, method]\n",
       "1871    [function, member, member, attribut, word, cla...\n",
       "1872    [element, includ, class, definit, accessmodifi...\n",
       "1873                        [variabl, function, prototyp]\n",
       "1874    [public, privat, variabl, initi, function, inc...\n",
       "1875                         [return, valu, accept, valu]\n",
       "1876    [class, definit, typic, includ, class, name, c...\n",
       "1877    [paramet, type, class, name, return, type, cod...\n",
       "1878             [data, member, class, variabl, function]\n",
       "1879       [constructor, function, variabl, nativ, class]\n",
       "1880                             [function, data, member]\n",
       "1881                    [data, member, function, definit]\n",
       "1883                     [constructor, function, definit]\n",
       "1884    [class, name, data, class, definit, function, ...\n",
       "1885    [class, definit, includ, definit, class, const...\n",
       "1886    [class, name, semicoln, end, defin, privat, bu...\n",
       "1887    [constructor, privat, public, variabl, functio...\n",
       "1888              [data, variabl, function, data, member]\n",
       "1889    [class, definit, includ, name, class, type, pa...\n",
       "1890          [class, variabl, class, function, prototyp]\n",
       "1891              [input, address, return, type, element]\n",
       "2132    [use, divid, conqur, techniqu, recurs, merg, b...\n",
       "2133    [merg, sort, work, remov, item, sepper, memori...\n",
       "2134    [divid, array, two, halv, sort, half, merg, tw...\n",
       "2135    [divid, two, sublist, sublist, break, length, ...\n",
       "2136    [merg, sort, use, divid, conquer, idea, divid,...\n",
       "2137    [divid, line, half, coninu, get, singl, valu, ...\n",
       "2138    [continu, split, array, half, sort, side, halv...\n",
       "2139    [merg, sort, split, array, element, smaller, a...\n",
       "2140                                     [divid, conquer]\n",
       "2141    [break, singl, array, mani, array, individu, e...\n",
       "2142    [merg, sort, break, array, half, continu, elem...\n",
       "2143    [merg, sort, divid, problem, half, organ, half...\n",
       "2144    [take, array, split, two, solv, simpler, probl...\n",
       "2145    [merg, sort, recurs, divid, array, half, one, ...\n",
       "2146    [merg, sort, recurs, divid, array, two, array,...\n",
       "2147    [merg, sort, continu, break, array, half, sort...\n",
       "2148    [take, array, split, half, sort, two, halvesei...\n",
       "2149    [split, larg, array, small, array, recur, arra...\n",
       "2150    [mergesort, divid, array, smaller, halv, combi...\n",
       "2151    [merg, sort, break, array, halv, compar, two, ...\n",
       "2152    [divid, data, twor, separ, array, sort, two, a...\n",
       "2153    [take, initi, array, split, two, temporari, sm...\n",
       "2154    [merg, sort, divid, data, halv, data, one, ele...\n",
       "2155    [merg, sort, use, divid, conquer, strategi, so...\n",
       "2156    [divid, recursuivli, big, array, two, array, s...\n",
       "2157    [divid, array, half, sort, half, call, self, t...\n",
       "2158    [merg, sort, take, array, split, half, send, h...\n",
       "2159    [merg, sort, split, array, two, halv, sort, tw...\n",
       "2160    [merg, sort, continu, divid, arrayor, set, con...\n",
       "2161    [merg, sort, split, array, element, smaller, s...\n",
       "Name: stemmed_tokens, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stemmed_tokens'] = data['tokenized'].apply(lambda x: \\\n",
    "    [PorterStemmer().stem(word) for word in x])\n",
    "data['stemmed_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ah-ma\\AppData\\Local\\Temp\\ipykernel_22008\\2219985963.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['lemmatized_tokens'] = data['tokenized'].apply(lambda x: \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1862    [name, class, file, parameter, must, take, per...\n",
       "1863    [access, specifier, function, oftentimes, cons...\n",
       "1864    [element, typically, included, class, definiti...\n",
       "1865    [class, user, defined, contains, member, data,...\n",
       "1866                     [member, function, data, member]\n",
       "1867    [function, variable, used, object, defined, cl...\n",
       "1868    [data, member, function, function, definition,...\n",
       "1869                     [return, type, input, parameter]\n",
       "1870                  [constructor, data, member, method]\n",
       "1871    [function, member, member, attribute, word, cl...\n",
       "1872    [element, included, class, definition, accessm...\n",
       "1873                      [variable, function, prototype]\n",
       "1874    [public, private, variable, initiation, functi...\n",
       "1875                     [return, value, accepted, value]\n",
       "1876    [class, definition, typically, includes, class...\n",
       "1877    [parameter, type, class, name, return, type, c...\n",
       "1878            [data, member, class, variable, function]\n",
       "1879     [constructor, function, variable, native, class]\n",
       "1880                             [function, data, member]\n",
       "1881                 [data, member, function, definition]\n",
       "1883                  [constructor, function, definition]\n",
       "1884    [class, name, data, class, definition, functio...\n",
       "1885    [class, definition, includes, definition, clas...\n",
       "1886    [class, name, semicoln, end, defination, priva...\n",
       "1887    [constructor, private, public, variable, funct...\n",
       "1888             [data, variable, function, data, member]\n",
       "1889    [class, definition, include, name, class, type...\n",
       "1890        [class, variable, class, function, prototype]\n",
       "1891              [input, address, return, type, element]\n",
       "2132    [us, divide, conqure, technique, recursively, ...\n",
       "2133    [merge, sort, work, removing, item, sepperate,...\n",
       "2134    [divide, array, two, half, sort, half, merges,...\n",
       "2135    [divide, two, sublists, sublists, break, lengt...\n",
       "2136    [merge, sort, us, divide, conquer, idea, divid...\n",
       "2137    [divide, line, half, coninuously, get, single,...\n",
       "2138    [continually, split, array, half, sort, side, ...\n",
       "2139    [merge, sort, split, array, element, smaller, ...\n",
       "2140                                    [divide, conquer]\n",
       "2141    [break, single, array, many, array, individual...\n",
       "2142    [merge, sort, break, array, half, continues, e...\n",
       "2143    [merge, sort, divide, problem, half, organizes...\n",
       "2144    [take, array, split, two, solve, simpler, prob...\n",
       "2145    [merge, sort, recursively, divide, array, half...\n",
       "2146    [merge, sort, recursively, divide, array, two,...\n",
       "2147    [merge, sort, continuously, break, array, half...\n",
       "2148    [take, array, split, half, sort, two, halvesei...\n",
       "2149    [split, large, array, small, array, recurs, ar...\n",
       "2150    [mergesort, divide, array, smaller, half, comb...\n",
       "2151    [merge, sort, break, array, half, comparing, t...\n",
       "2152    [divide, data, twor, separate, array, sort, tw...\n",
       "2153    [take, initial, array, split, two, temporary, ...\n",
       "2154    [merge, sort, divide, data, half, data, one, e...\n",
       "2155    [merge, sort, us, divide, conquer, strategy, s...\n",
       "2156    [divide, recursuivly, big, array, two, array, ...\n",
       "2157    [divide, array, half, sort, half, calling, sel...\n",
       "2158    [merge, sort, take, array, split, half, sends,...\n",
       "2159    [merge, sort, split, array, two, half, sort, t...\n",
       "2160    [merge, sort, continually, divide, arrayor, se...\n",
       "2161    [merge, sort, split, array, element, smaller, ...\n",
       "Name: lemmatized_tokens, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatized_tokens'] = data['tokenized'].apply(lambda x: \\\n",
    "    [WordNetLemmatizer().lemmatize(word) for word in x])\n",
    "data['lemmatized_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating word embeddings using BagOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ah-ma\\AppData\\Local\\Temp\\ipykernel_22008\\4055446699.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['lemmatized_text'] = data['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accepted</th>\n",
       "      <th>access</th>\n",
       "      <th>accessmodifier</th>\n",
       "      <th>according</th>\n",
       "      <th>address</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>also</th>\n",
       "      <th>answer</th>\n",
       "      <th>array</th>\n",
       "      <th>arrayor</th>\n",
       "      <th>...</th>\n",
       "      <th>used</th>\n",
       "      <th>user</th>\n",
       "      <th>usually</th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "      <th>version</th>\n",
       "      <th>way</th>\n",
       "      <th>whole</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accepted  access  accessmodifier  according  address  algorithm  also  \\\n",
       "0         0       0               0          0        0          0     1   \n",
       "1         0       1               0          0        0          0     0   \n",
       "2         0       0               0          0        0          0     0   \n",
       "3         0       0               0          0        0          0     0   \n",
       "4         0       0               0          0        0          0     0   \n",
       "\n",
       "   answer  array  arrayor  ...  used  user  usually  value  variable  version  \\\n",
       "0       0      0        0  ...     0     0        0      0         0        0   \n",
       "1       0      0        0  ...     0     0        0      0         0        0   \n",
       "2       0      0        0  ...     1     0        2      0         0        0   \n",
       "3       0      0        0  ...     1     1        0      0         0        0   \n",
       "4       0      0        0  ...     0     0        0      0         0        0   \n",
       "\n",
       "   way  whole  word  work  \n",
       "0    0      0     0     0  \n",
       "1    0      0     0     0  \n",
       "2    0      0     0     0  \n",
       "3    0      0     0     0  \n",
       "4    0      0     0     0  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatized_text'] = data['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
    "vectorizer = CountVectorizer()\n",
    "bof_model = vectorizer.fit(data['lemmatized_text'].tolist())\n",
    "bof_vect = bof_model.transform(data['lemmatized_text'])\n",
    "bow_df = pd.DataFrame(bof_vect.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating word embeddings using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accepted</th>\n",
       "      <th>access</th>\n",
       "      <th>accessmodifier</th>\n",
       "      <th>according</th>\n",
       "      <th>address</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>also</th>\n",
       "      <th>answer</th>\n",
       "      <th>array</th>\n",
       "      <th>arrayor</th>\n",
       "      <th>...</th>\n",
       "      <th>used</th>\n",
       "      <th>user</th>\n",
       "      <th>usually</th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "      <th>version</th>\n",
       "      <th>way</th>\n",
       "      <th>whole</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.521989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29481</td>\n",
       "      <td>0.349919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accepted    access  accessmodifier  according  address  algorithm  \\\n",
       "0       0.0  0.000000             0.0        0.0      0.0        0.0   \n",
       "1       0.0  0.519186             0.0        0.0      0.0        0.0   \n",
       "2       0.0  0.000000             0.0        0.0      0.0        0.0   \n",
       "3       0.0  0.000000             0.0        0.0      0.0        0.0   \n",
       "4       0.0  0.000000             0.0        0.0      0.0        0.0   \n",
       "\n",
       "       also  answer  array  arrayor  ...     used      user   usually  value  \\\n",
       "0  0.306395     0.0    0.0      0.0  ...  0.00000  0.000000  0.000000    0.0   \n",
       "1  0.000000     0.0    0.0      0.0  ...  0.00000  0.000000  0.000000    0.0   \n",
       "2  0.000000     0.0    0.0      0.0  ...  0.21989  0.000000  0.521989    0.0   \n",
       "3  0.000000     0.0    0.0      0.0  ...  0.29481  0.349919  0.000000    0.0   \n",
       "4  0.000000     0.0    0.0      0.0  ...  0.00000  0.000000  0.000000    0.0   \n",
       "\n",
       "   variable  version  way  whole  word  work  \n",
       "0       0.0      0.0  0.0    0.0   0.0   0.0  \n",
       "1       0.0      0.0  0.0    0.0   0.0   0.0  \n",
       "2       0.0      0.0  0.0    0.0   0.0   0.0  \n",
       "3       0.0      0.0  0.0    0.0   0.0   0.0  \n",
       "4       0.0      0.0  0.0    0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_model = tfidf.fit(data['lemmatized_text'])\n",
    "tfidf_vect = tfidf_model.transform(data['lemmatized_text'])\n",
    "tfidf_df = pd.DataFrame(tfidf_vect.toarray(), columns=tfidf.get_feature_names_out())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating word embeddings using Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(data['lemmatized_tokens'], vector_size=30, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ah-ma\\AppData\\Local\\Temp\\ipykernel_22008\\319534505.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['w2v_embeddings'] = data['lemmatized_tokens'].apply(lambda x: vectorize_answer(x, w2v_model))\n"
     ]
    }
   ],
   "source": [
    "def vectorize_answer(answer_tokens, word2vec_model):\n",
    "    answer_vector = np.mean([word2vec_model.wv.get_vector(word) for word in answer_tokens if word in word2vec_model.wv] \\\n",
    "        or [np.zeros(word2vec_model.vector_size)], axis=0)\n",
    "    return answer_vector\n",
    "\n",
    "data['w2v_embeddings'] = data['lemmatized_tokens'].apply(lambda x: vectorize_answer(x, w2v_model))\n",
    "w2v_df = pd.DataFrame(data['w2v_embeddings'].values.tolist(), index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(w2v_df, data['score'], test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE Score: 0.3627122499809037\n",
      "SVR RMSE Score: 0.6022559671608939\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(kernel='rbf', C=10000, gamma=0.1, tol=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred = svr.predict(X_test)\n",
    "print('SVR MSE Score:', mean_squared_error(y_test, y_pred))\n",
    "print('SVR RMSE Score:', root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE Score: 0.5040098460750949\n",
      "Linear Regression RMSE Score: 0.7099365084816353\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=True)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print('Linear Regression MSE Score:', mean_squared_error(y_test, y_pred))\n",
    "print('Linear Regression RMSE Score:', root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor MSE Score: 0.9120370370370369\n",
      "Decision Tree Regressor RMSE Score: 0.955006302092838\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth=5,random_state=0)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_pred = dtr.predict(X_test)\n",
    "print('Decision Tree Regressor MSE Score:', mean_squared_error(y_test, y_pred))\n",
    "print('Decision Tree Regressor RMSE Score:', root_mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Language Modeling - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = pd.read_csv('data/twitter_training.csv')\n",
    "tweets_val = pd.read_csv('data/twitter_validation.csv')\n",
    "tweets_val.drop(['id','game'],axis=1,inplace=True)\n",
    "tweets_train.drop(['id','game'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to clean tweets\n",
    "def processTweet(tweet):\n",
    "    if isinstance(tweet, float):\n",
    "        return str(tweet)\n",
    "    # remove user handles tagged in the tweet\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    # remove words that start with th dollar sign    \n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    tweet = re.sub(r'(?:^|[\\s,])([\\w-]+\\.[a-z]{2,}\\S*)\\b','',tweet)\n",
    "    # remove hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    # remove all kinds of punctuations and special characters\n",
    "    punkt = string.punctuation + r'''`‘’)(+÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”،.”…“–ـ”.°ा'''\n",
    "    tweet = tweet.translate(str.maketrans('', '', punkt))\n",
    "    # remove words with 2 or fewer letters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    # remove HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    # remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    # remove stopwords\n",
    "    tweet = re.sub(r'\\b('+ '|'.join(stopword for stopword in stopwords.words('english'))+ r')\\b', '', tweet)\n",
    "    # remove single space remaining at the front of the tweet.\n",
    "    tweet = tweet.lstrip(' ')\n",
    "    tweet = tweet.rstrip(' ')\n",
    "    # remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "    tweet = ''.join(c for c in tweet if c <= '\\uffff')\n",
    "    tweet = re.sub(r'([^\\u1F600-\\u1F6FF\\s])','', tweet)\n",
    "    # lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # remove extra spaces\n",
    "    tweet = re.sub(r'[\\s]{2, }', ' ', tweet)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding and dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>getting borderlands   murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>coming  borders   kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>getting borderlands   kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>coming borderlands   murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>getting  borderlands   murder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                           text\n",
       "0      3   getting borderlands   murder\n",
       "1      3         coming  borders   kill\n",
       "2      3     getting borderlands   kill\n",
       "3      3    coming borderlands   murder\n",
       "5      3  getting  borderlands   murder"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train['clean_text'] = tweets_train['text'].apply(processTweet)\n",
    "tweets_train['label'] = LabelEncoder().fit_transform(tweets_train['label'])\n",
    "tweets_train.drop_duplicates(subset=['clean_text'],inplace=True)\n",
    "tweets_train.drop(['text'],axis=1,inplace=True)\n",
    "tweets_train.rename(columns={\"clean_text\": \"text\"},inplace=True)\n",
    "tweets_train.dropna(inplace=True)\n",
    "tweets_train.drop(tweets_train[tweets_train['text'] == ''].index, inplace = True)\n",
    "tweets_train.drop(tweets_train[tweets_train['text'] == ' '].index, inplace = True)\n",
    "tweets_train.drop(tweets_train[tweets_train['text'] == 'nan'].index, inplace = True)\n",
    "tweets_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mentioned facebook   struggling  motivation  r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>bbc news amazon boss jeff bezos rejects claims...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>why pay  word  functions poorly chromebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>csgo matchmaking full closet hacking  truly aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>now  president slapping americans  face  reall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  mentioned facebook   struggling  motivation  r...\n",
       "1      2  bbc news amazon boss jeff bezos rejects claims...\n",
       "2      1        why pay  word  functions poorly chromebook \n",
       "3      1  csgo matchmaking full closet hacking  truly aw...\n",
       "4      2  now  president slapping americans  face  reall..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_val['clean_text'] = tweets_val['text'].apply(processTweet)\n",
    "tweets_val['label'] = LabelEncoder().fit_transform(tweets_val['label'])\n",
    "tweets_val.drop_duplicates(subset=['clean_text'],inplace=True)\n",
    "tweets_val.head()\n",
    "tweets_val.drop(['text'],axis=1,inplace=True)\n",
    "tweets_val.rename(columns={\"clean_text\": \"text\"},inplace=True)\n",
    "tweets_val.dropna(inplace=True)\n",
    "tweets_val.drop(tweets_val[tweets_val['text'] == ''].index, inplace = True)\n",
    "tweets_val.drop(tweets_val[tweets_val['text'] == ' '].index, inplace = True)\n",
    "tweets_val.drop(tweets_val[tweets_val['text'] == 'nan'].index, inplace = True)\n",
    "tweets_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train['tokenized'] = tweets_train['text'].apply(lambda x: word_tokenize(x))\n",
    "tweets_val['tokenized'] = tweets_val['text'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train['stemmed_tokens'] = tweets_train['tokenized'].apply(lambda x: \\\n",
    "    [PorterStemmer().stem(word) for word in x])\n",
    "tweets_val['stemmed_tokens'] = tweets_val['tokenized'].apply(lambda x: \\\n",
    "    [PorterStemmer().stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train['lemmatized_tokens'] = tweets_train['tokenized'].apply(lambda x: \\\n",
    "    [WordNetLemmatizer().lemmatize(word) for word in x])\n",
    "tweets_val['lemmatized_tokens'] = tweets_val['tokenized'].apply(lambda x: \\\n",
    "    [WordNetLemmatizer().lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>00011</th>\n",
       "      <th>00014</th>\n",
       "      <th>00015</th>\n",
       "      <th>00015cant</th>\n",
       "      <th>00016</th>\n",
       "      <th>00054</th>\n",
       "      <th>00105</th>\n",
       "      <th>00107</th>\n",
       "      <th>0023</th>\n",
       "      <th>...</th>\n",
       "      <th>اللعبه</th>\n",
       "      <th>حبيت</th>\n",
       "      <th>خلاص</th>\n",
       "      <th>خلاصunk</th>\n",
       "      <th>عبر</th>\n",
       "      <th>فيديو</th>\n",
       "      <th>٩ᴗ۶</th>\n",
       "      <th>घरच</th>\n",
       "      <th>การออกอากาศของฉ</th>\n",
       "      <th>นจาก</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  00011  00014  00015  00015cant  00016  00054  00105  00107  0023  ...  \\\n",
       "0    0      0      0      0          0      0      0      0      0     0  ...   \n",
       "1    0      0      0      0          0      0      0      0      0     0  ...   \n",
       "2    0      0      0      0          0      0      0      0      0     0  ...   \n",
       "3    0      0      0      0          0      0      0      0      0     0  ...   \n",
       "4    0      0      0      0          0      0      0      0      0     0  ...   \n",
       "\n",
       "   اللعبه  حبيت  خلاص  خلاصunk  عبر  فيديو  ٩ᴗ۶  घरच  การออกอากาศของฉ  นจาก  \n",
       "0       0     0     0        0    0      0    0    0                0     0  \n",
       "1       0     0     0        0    0      0    0    0                0     0  \n",
       "2       0     0     0        0    0      0    0    0                0     0  \n",
       "3       0     0     0        0    0      0    0    0                0     0  \n",
       "4       0     0     0        0    0      0    0    0                0     0  \n",
       "\n",
       "[5 rows x 31510 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_train['lemmatized_text'] = tweets_train['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
    "vectorizer = CountVectorizer()\n",
    "bof_model = vectorizer.fit(tweets_train['lemmatized_text'].tolist())\n",
    "bof_vect = bof_model.transform(tweets_train['lemmatized_text'])\n",
    "bow_df = pd.DataFrame(bof_vect.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "bow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>00011</th>\n",
       "      <th>00014</th>\n",
       "      <th>00015</th>\n",
       "      <th>00015cant</th>\n",
       "      <th>00016</th>\n",
       "      <th>00054</th>\n",
       "      <th>00105</th>\n",
       "      <th>00107</th>\n",
       "      <th>0023</th>\n",
       "      <th>...</th>\n",
       "      <th>اللعبه</th>\n",
       "      <th>حبيت</th>\n",
       "      <th>خلاص</th>\n",
       "      <th>خلاصunk</th>\n",
       "      <th>عبر</th>\n",
       "      <th>فيديو</th>\n",
       "      <th>٩ᴗ۶</th>\n",
       "      <th>घरच</th>\n",
       "      <th>การออกอากาศของฉ</th>\n",
       "      <th>นจาก</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31510 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  00011  00014  00015  00015cant  00016  00054  00105  00107  0023  ...  \\\n",
       "0  0.0    0.0    0.0    0.0        0.0    0.0    0.0    0.0    0.0   0.0  ...   \n",
       "1  0.0    0.0    0.0    0.0        0.0    0.0    0.0    0.0    0.0   0.0  ...   \n",
       "2  0.0    0.0    0.0    0.0        0.0    0.0    0.0    0.0    0.0   0.0  ...   \n",
       "3  0.0    0.0    0.0    0.0        0.0    0.0    0.0    0.0    0.0   0.0  ...   \n",
       "4  0.0    0.0    0.0    0.0        0.0    0.0    0.0    0.0    0.0   0.0  ...   \n",
       "\n",
       "   اللعبه  حبيت  خلاص  خلاصunk  عبر  فيديو  ٩ᴗ۶  घरच  การออกอากาศของฉ  นจาก  \n",
       "0     0.0   0.0   0.0      0.0  0.0    0.0  0.0  0.0              0.0   0.0  \n",
       "1     0.0   0.0   0.0      0.0  0.0    0.0  0.0  0.0              0.0   0.0  \n",
       "2     0.0   0.0   0.0      0.0  0.0    0.0  0.0  0.0              0.0   0.0  \n",
       "3     0.0   0.0   0.0      0.0  0.0    0.0  0.0  0.0              0.0   0.0  \n",
       "4     0.0   0.0   0.0      0.0  0.0    0.0  0.0  0.0              0.0   0.0  \n",
       "\n",
       "[5 rows x 31510 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_model = tfidf.fit(tweets_train['lemmatized_text'])\n",
    "tfidf_vect = tfidf_model.transform(tweets_train['lemmatized_text'])\n",
    "tfidf_df = pd.DataFrame(tfidf_vect.toarray(), columns=tfidf.get_feature_names_out())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(tweets_train['lemmatized_tokens'], vector_size=100, window=50, min_count=1, workers=4, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train['w2v_embeddings'] = tweets_train['lemmatized_tokens'].apply(lambda x: vectorize_answer(x, w2v_model))\n",
    "w2v_df_train = pd.DataFrame(tweets_train['w2v_embeddings'].values.tolist(), index=tweets_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_val['w2v_embeddings'] = tweets_val['lemmatized_tokens'].apply(lambda x: vectorize_answer(x, w2v_model))\n",
    "w2v_df_val = pd.DataFrame(tweets_val['w2v_embeddings'].values.tolist(), index=tweets_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(w2v_df_train, tweets_train['label'])\n",
    "y_pred = svc.predict(w2v_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       172\n",
      "           1       0.83      0.94      0.88       264\n",
      "           2       0.93      0.77      0.84       276\n",
      "           3       0.86      0.91      0.88       275\n",
      "\n",
      "    accuracy                           0.87       987\n",
      "   macro avg       0.87      0.86      0.86       987\n",
      "weighted avg       0.87      0.87      0.87       987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(tweets_val['label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8662613981762918\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy: {accuracy_score(tweets_val['label'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ah-ma\\Desktop\\Samashi\\Studying\\Master\\S2\\SMA & NLP\\NLP - Pr Lotfi El Aachak\\NLP_Labs\\NLP_Labs\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:287: ConvergenceWarning: Line search of Newton solver NewtonCholeskySolver at iteration #5 did no converge after 21 line search refinement iterations. It will now resort to lbfgs instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ah-ma\\Desktop\\Samashi\\Studying\\Master\\S2\\SMA & NLP\\NLP - Pr Lotfi El Aachak\\NLP_Labs\\NLP_Labs\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:287: ConvergenceWarning: Line search of Newton solver NewtonCholeskySolver at iteration #7 did no converge after 21 line search refinement iterations. It will now resort to lbfgs instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ah-ma\\Desktop\\Samashi\\Studying\\Master\\S2\\SMA & NLP\\NLP - Pr Lotfi El Aachak\\NLP_Labs\\NLP_Labs\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_glm\\_newton_solver.py:287: ConvergenceWarning: Line search of Newton solver NewtonCholeskySolver at iteration #6 did no converge after 21 line search refinement iterations. It will now resort to lbfgs instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l2',solver='newton-cholesky',multi_class='ovr',tol=1e-6)\n",
    "logreg.fit(w2v_df_train, tweets_train['label'])\n",
    "y_pred = logreg.predict(w2v_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.16      0.23       172\n",
      "           1       0.51      0.73      0.60       264\n",
      "           2       0.52      0.39      0.45       276\n",
      "           3       0.54      0.66      0.59       275\n",
      "\n",
      "    accuracy                           0.51       987\n",
      "   macro avg       0.49      0.48      0.47       987\n",
      "weighted avg       0.50      0.51      0.49       987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression: \")\n",
    "print(classification_report(tweets_val['label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.5146909827760892\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logistic Regression accuracy: {accuracy_score(tweets_val['label'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbm = GaussianNB()\n",
    "nbm.fit(w2v_df_train, tweets_train['label'])\n",
    "y_pred = nbm.predict(w2v_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.31      0.31       172\n",
      "           1       0.52      0.61      0.56       264\n",
      "           2       0.46      0.38      0.42       276\n",
      "           3       0.51      0.53      0.52       275\n",
      "\n",
      "    accuracy                           0.47       987\n",
      "   macro avg       0.45      0.46      0.45       987\n",
      "weighted avg       0.47      0.47      0.47       987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes: \")\n",
    "print(classification_report(tweets_val['label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.47213779128672745\n"
     ]
    }
   ],
   "source": [
    "print(f\"Naive Bayes accuracy: {accuracy_score(tweets_val['label'], y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ah-ma\\Desktop\\Samashi\\Studying\\Master\\S2\\SMA & NLP\\NLP - Pr Lotfi El Aachak\\NLP_Labs\\NLP_Labs\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "adab = AdaBoostClassifier()\n",
    "adab.fit(w2v_df_train, tweets_train['label'])\n",
    "y_pred = adab.predict(w2v_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.20      0.25       172\n",
      "           1       0.49      0.68      0.57       264\n",
      "           2       0.49      0.33      0.39       276\n",
      "           3       0.50      0.59      0.54       275\n",
      "\n",
      "    accuracy                           0.48       987\n",
      "   macro avg       0.45      0.45      0.44       987\n",
      "weighted avg       0.46      0.48      0.46       987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AdaBoost: \")\n",
    "print(classification_report(tweets_val['label'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost accuracy: 0.475177304964539\n"
     ]
    }
   ],
   "source": [
    "print(f\"AdaBoost accuracy: {accuracy_score(tweets_val['label'], y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
